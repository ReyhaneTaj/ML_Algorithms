{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZ74jBELn/e8SIetUqDVL2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReyhaneTaj/ML_Algorithms/blob/main/LinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aIeKQaZ7l9e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression: Concept and Implementation\n",
        "\n",
        "## What is Linear Regression?\n",
        "Linear Regression is a supervised machine learning model used for regression tasks. It predicts the value of a target variable based on the linear relationship between the target and one or more predictor variables.\n",
        "\n",
        "- **Model Structure**: Linear regression fits a linear equation to the observed data.\n",
        "- **Equation**: For a single predictor, the equation is \\( y = \\beta_0 + \\beta_1 x + \\epsilon \\), where:\n",
        "  - \\( y \\) is the target variable.\n",
        "  - \\( x \\) is the predictor variable.\n",
        "  - \\( \\beta_0 \\) is the intercept.\n",
        "  - \\( \\beta_1 \\) is the slope (coefficient).\n",
        "  - \\( \\epsilon \\) is the error term.\n",
        "\n",
        "## Types of Linear Regression\n",
        "1. **Simple Linear Regression**: Involves a single predictor variable.\n",
        "2. **Multiple Linear Regression**: Involves multiple predictor variables.\n",
        "\n",
        "## Assumptions of Linear Regression\n",
        "1. **Linearity**: The relationship between the predictors and the target is linear.\n",
        "2. **Independence**: Observations are independent of each other.\n",
        "3. **Homoscedasticity**: Constant variance of the errors.\n",
        "4. **Normality**: The residuals (errors) of the model are normally distributed.\n",
        "5. **No Multicollinearity**: Predictors are not highly correlated with each other.\n",
        "\n",
        "## How Linear Regression Works\n",
        "1. **Model Training**: The model learns the best-fitting line by minimizing the sum of squared residuals (errors) between the predicted and actual values.\n",
        "2. **Prediction**: New data is passed through the learned linear equation to make predictions.\n",
        "\n",
        "## Advantages\n",
        "- **Simplicity**: Easy to understand and implement.\n",
        "- **Interpretability**: Coefficients provide clear insights into the relationship between predictors and the target variable.\n",
        "- **Computational Efficiency**: Requires minimal computational resources.\n",
        "\n",
        "## Disadvantages\n",
        "- **Assumptions**: Assumes a linear relationship between predictors and the target, which may not hold in all cases.\n",
        "- **Outliers**: Sensitive to outliers, which can disproportionately influence the model.\n",
        "- **Multicollinearity**: Can be problematic if predictors are highly correlated.\n",
        "- **Extrapolation**: Poor performance on data outside the range of the training set.\n",
        "\n",
        "## Implementation in Google Colab\n",
        "Let's implement a Linear Regression model using the Boston housing dataset.\n",
        "\n",
        "### Code Implementation\n",
        "\n"
      ],
      "metadata": {
        "id": "DxjPHo0P7nvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Step 2: Load Dataset\n",
        "data = load_boston()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Step 3: Split Dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 4: Train Linear Regression Model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Make Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 6: Evaluate the Model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R^2 Score: {r2}\")\n",
        "\n",
        "# Visualize the Results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred, color='blue')\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', lw=2)\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('Actual vs Predicted')\n",
        "plt.show()\n",
        "\n",
        "# Residual Plot\n",
        "residuals = y_test - y_pred\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_pred, residuals, color='blue')\n",
        "plt.axhline(y=0, color='red', linestyle='--')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot')\n",
        "plt.show()\n",
        "\n",
        "# Distribution of Residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(residuals, kde=True, color='blue')\n",
        "plt.xlabel('Residuals')\n",
        "plt.title('Distribution of Residuals')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xPG4h3Pn8Zkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison with Other Models**\n",
        "\n",
        "**Accuracy:** Linear regression can be less accurate compared to more complex models, especially if the relationship is not linear.\n",
        "\n",
        "**Complexity:** Linear regression is less complex compared to models like Random Forests or Neural Networks.\n",
        "\n",
        "**Interpretability:** Linear regression is highly interpretable, with coefficients directly showing the impact of predictors.\n",
        "**Conclusion**\n",
        "Linear Regression is a fundamental machine learning algorithm used for predicting continuous values. Its simplicity and interpretability make it a good starting point for regression problems, although it may be limited by assumptions of linearity and sensitivity to outliers."
      ],
      "metadata": {
        "id": "wA9SRndh8sfG"
      }
    }
  ]
}